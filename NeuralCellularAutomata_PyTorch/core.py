# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/00_core.ipynb.

# %% auto 0
__all__ = ['def_device', 'CHANNEL_N', 'TARGET_PADDING', 'TARGET_SIZE', 'POOL_SIZE', 'CELL_FIRE_RATE', 'filters', 'load_image',
           'perchannel_conv', 'alive', 'CAModel', 'display_animation', 'grow_animation']

# %% ../nbs/00_core.ipynb 3
from PIL import Image

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.animation as animation

from IPython.display import HTML

import fastcore.all as fc

from functools import partial
import torch
import torch.nn as nn
import torch.nn.functional as F

# %% ../nbs/00_core.ipynb 5
# setting a default device 
def_device = 'mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu'

# %% ../nbs/00_core.ipynb 7
CHANNEL_N = 16
TARGET_PADDING = 16
TARGET_SIZE = 40

POOL_SIZE = 1024
CELL_FIRE_RATE = 0.5

# %% ../nbs/00_core.ipynb 11
def load_image(path):
    "Load the image specified by `path` and return a `torch.tensor` version of the image with shape B, C, H, W, already on the default device"
    
    img = Image.open(path).resize((TARGET_SIZE, TARGET_SIZE))
    # Convert the image to numpy array 
    img = np.array(img)
    img = img.astype(np.float32) / 255.0

    # Display the image
    plt.imshow(img)
    plt.show()
    
    img_tensor = torch.tensor(img).permute(2, 0, 1)[None].to(def_device)
    
    return img_tensor

# %% ../nbs/00_core.ipynb 14
filters = torch.stack([
    torch.tensor([[0.0,0.0,0.0],[0.0,1.0,0.0],[0.0,0.0,0.0]]),      # Identity filter 
    torch.tensor([[-1.0,0.0,1.0],[-2.0,0.0,2.0],[-1.0,0.0,1.0]]),   # Vertical sobel filter
    torch.tensor([[-1.0,0.0,1.0],[-2.0,0.0,2.0],[-1.0,0.0,1.0]]).T  # Horizontal sobel filter
]).to(def_device)

# %% ../nbs/00_core.ipynb 17
def perchannel_conv(x, filters):
    b, c, h, w = x.shape
    y = x.reshape(b * c, 1, h, w)
    y = F.pad(y, (1, 1, 1, 1), mode='circular')
    y = F.conv2d(y, filters[:, None])
    return y.reshape(b, -1, h, w)

# %% ../nbs/00_core.ipynb 22
def alive(x, threshold=0.1):
    x = F.pad(x, (1, 1, 1, 1), mode='circular')
    return F.max_pool2d(x, 3, stride=1, padding=0) > threshold

# %% ../nbs/00_core.ipynb 23
class CAModel(nn.Module):
    
    def __init__(self, channel_n, update_rate=0.5):
        super().__init__()
        
        self.channel_n = channel_n
        self.update_rate = update_rate
        
        self.brain = nn.Sequential(
            nn.Conv2d(channel_n * 3, 128, kernel_size=1), # pixel-wise mlp 
            nn.ReLU(),
            nn.Conv2d(128, self.channel_n, kernel_size=1, bias=False)
        )
        
        # this network is used to calculate the change of the features, so initially, we dont want to suggest any changes
        # thus we set the output weights to zero
        with torch.no_grad():
            self.brain[-1].weight.zero_()

    def step(self, x, update_rate=None):
        
        # -- Perception -- (apply the filters to the input)
        y = perchannel_conv(x, filters)
        
        # -- Update Rule -- (pass the input through the brain)
        y = self.brain(y)

        # -- Stochastic cell update --
        B, C, H, W = y.shape
        update_rate = update_rate or self.update_rate # if update_rate is not given, use the default value
        update_mask = (torch.rand(B, 1, H, W).to(def_device) + update_rate).floor() 
        x = x + y * update_mask # update only a fraction of the cells

        # -- Alive masking --
        alive_mask = alive(x[:, 3:4, :, :], threshold=0.1) # we use 3:4 to keep the dimension
        x = x * alive_mask

        return x

    def forward(self, x, steps=1, update_rate=None):
        for i in range(steps):
            x = self.step(x, update_rate=update_rate)
        return x

# %% ../nbs/00_core.ipynb 28
def display_animation(images): # A list containing the frames of the animation. Each frame should be of shape [H, W, 4]
    fig = plt.figure(figsize=(6, 6))
    plt.axis('off')
    ims = [[plt.imshow(image, animated=True)] for image in images]
    # display animation in jupyter notebook
    ani = animation.ArtistAnimation(fig, ims, interval=50, repeat_delay=1000)
    plt.close()
    # display HTML
    return HTML(ani.to_jshtml())    

# %% ../nbs/00_core.ipynb 31
@fc.patch
def grow_animation(self: CAModel, seed, steps, update_rate=None):
    x = seed.clone()
    images = [torch.clamp(x[0, :4].detach().cpu().permute(1, 2, 0), 0, 1)]
    for _ in range(steps):
        x = self.step(x, update_rate=update_rate)
        images.append(torch.clamp(x[0, :4].detach().cpu().permute(1, 2, 0), 0, 1))
    return images
