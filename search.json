[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Neural Cellular Automata - PyTorch",
    "section": "",
    "text": "To run the code: 1. Clone the repo 2. CD inside the main directory and run `pip install -e .’\nThis project is based on nbdev, so please check their documentation for further information."
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "Neural Cellular Automata - PyTorch",
    "section": "",
    "text": "To run the code: 1. Clone the repo 2. CD inside the main directory and run `pip install -e .’\nThis project is based on nbdev, so please check their documentation for further information."
  },
  {
    "objectID": "index.html#how-to-read",
    "href": "index.html#how-to-read",
    "title": "Neural Cellular Automata - PyTorch",
    "section": "How to read",
    "text": "How to read\nInside the nbs there are the notebooks that implement the proposed method. The notebooks are numbered in ascending ordered and every notebook uses tools developed in the previous ones.\nThere are 3 main experiments (using the titles from the original version).\n\n1. Learning to Grow\nIn this experiment we train the automato to generate from an original state (seed) to its final form.\n\n\n\nAlt Text\n\n\n\n\n2. What Persists, Exists\nIn this experiment we train the automato to maintain its final form as time passes.\n\n\n\nAlt Text\n\n\n\n\n3. Learning to Regenerate\nIn this experiment, we train the automaton to recover from specific types of corruption that may be applied to it."
  },
  {
    "objectID": "index.html#notes",
    "href": "index.html#notes",
    "title": "Neural Cellular Automata - PyTorch",
    "section": "Notes",
    "text": "Notes\n\nIn case the loss in experiments 2 or 3 is not dropping restart the notebook. It seems that the network converges to a local minima where it kills all cells from the first step and thus this state cannot change in the process. A possible fix would be to train the network solely on the growing task and then use the pool to train the model in achieving percistance and regenaration abilities."
  },
  {
    "objectID": "learningtoregenerate.html",
    "href": "learningtoregenerate.html",
    "title": "Experiment 3: Learning to regenerate",
    "section": "",
    "text": "batch_size = 8\nn_epochs = 8000\npath = '../images/emoji_u1f98e.png'\nimg_tensor = load_image(path)"
  },
  {
    "objectID": "learningtoregenerate.html#test-the-reconstruction-ability-of-a-model",
    "href": "learningtoregenerate.html#test-the-reconstruction-ability-of-a-model",
    "title": "Experiment 3: Learning to regenerate",
    "section": "Test the reconstruction ability of a model",
    "text": "Test the reconstruction ability of a model\n\n# Generate an automato which we want to corrupt\ngenerated = ca(seed, steps=96).detach()\n\n\nCorruption 1:\n\ncorrupted_input1 = generated.clone()\ncorrupted_input1[..., 20:] = 0\n\nplt.imshow(corrupted_input1[0].permute(1, 2, 0)[:, :, :4].cpu())\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n&lt;matplotlib.image.AxesImage&gt;\n\n\n\n\n\n\nimages = ca.grow_animation(corrupted_input1, 300)\ndisplay_animation(images)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\nCorruption 2:\n\ncorrupted_input2 = generated.clone()\ncorrupted_input2[..., :20,:] = 0\n\nplt.imshow(corrupted_input2[0].permute(1, 2, 0)[:, :, :4].cpu())\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n&lt;matplotlib.image.AxesImage&gt;\n\n\n\n\n\n\nimages = ca.grow_animation(corrupted_input2, 300)\ndisplay_animation(images)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "learningtogrow.html",
    "href": "learningtogrow.html",
    "title": "Experiment 1: Learning to Grow",
    "section": "",
    "text": "path = '../images/emoji_u1f98e.png'\n\n\nimg_tensor = load_image(path)\n\n\n\n\n\nCreate a starting seed\nCreate a grid of shape 1, 16, H, W initialized with zeros, where all elements are set to 0.\nPlace a single cell in the center of the grid. This central cell should have all channels (except for RGB) set to 1. The RGB channels of the seed cell are intentionally set to zero to ensure visibility on the white background.\n\nseed.shape\n\ntorch.Size([1, 16, 40, 40])\n\n\n\nplt.imshow(seed[0, :4].detach().cpu().permute(1, 2, 0))\nplt.show()\n\n\n\n\n\n\nTraining Loop\n\n# training hyperparameters \nn_epochs = 8000\nbatch_size = 8\n\nlr = 2e-3\nlr_gamma = 0.9999\nbetas = (0.5, 0.5)\n\n\n# initialize the model\nca = CAModel(CHANNEL_N).to(def_device)\n\n\n# optimization\nimport torch.optim as optim\n\noptimizer = torch.optim.Adam(ca.parameters(), lr=lr, betas=betas)\nscheduler = optim.lr_scheduler.ExponentialLR(optimizer, lr_gamma)\n\n\n# create the input to the network and the target\nmodel_in = seed.repeat(batch_size, 1, 1, 1)\ntarget = img_tensor.repeat(batch_size, 1, 1, 1)\n\n\nfor i in tqdm(range(n_epochs)):\n    optimizer.zero_grad()\n    steps = torch.randint(64, 96, (1,)).item()\n    res = ca(model_in, steps=steps)\n\n    loss = F.mse_loss(res[:, :4], target) # we only care about the RGBA channels\n    if i%500 == 0:\n        print(f\"Epoch: {i} Loss: {loss.item()}\")\n    loss.backward()\n    optimizer.step()\n    scheduler.step()\n\n  0%|                                        | 1/8000 [00:00&lt;1:39:26,  1.34it/s]  6%|██▌                                     | 503/8000 [00:34&lt;08:02, 15.54it/s] 13%|████▉                                  | 1003/8000 [01:09&lt;08:05, 14.42it/s] 19%|███████▎                               | 1503/8000 [01:43&lt;07:14, 14.96it/s] 25%|█████████▊                             | 2003/8000 [02:18&lt;07:01, 14.22it/s] 31%|████████████▏                          | 2503/8000 [02:52&lt;06:10, 14.84it/s] 38%|██████████████▋                        | 3003/8000 [03:26&lt;05:50, 14.26it/s] 44%|█████████████████                      | 3503/8000 [04:01&lt;05:11, 14.42it/s] 50%|███████████████████▌                   | 4003/8000 [04:35&lt;04:39, 14.31it/s] 56%|█████████████████████▉                 | 4503/8000 [05:10&lt;03:48, 15.28it/s] 63%|████████████████████████▍              | 5003/8000 [05:44&lt;03:07, 16.01it/s] 69%|██████████████████████████▊            | 5503/8000 [06:18&lt;02:55, 14.20it/s] 75%|█████████████████████████████▎         | 6003/8000 [06:52&lt;02:13, 15.00it/s] 81%|███████████████████████████████▋       | 6503/8000 [07:26&lt;01:43, 14.48it/s] 88%|██████████████████████████████████▏    | 7003/8000 [08:00&lt;01:08, 14.51it/s] 94%|████████████████████████████████████▌  | 7503/8000 [08:35&lt;00:33, 14.86it/s]100%|███████████████████████████████████████| 8000/8000 [09:08&lt;00:00, 14.58it/s]\n\n\nEpoch: 0 Loss: 0.11318174749612808\nEpoch: 500 Loss: 0.011708867736160755\nEpoch: 1000 Loss: 0.008278374560177326\nEpoch: 1500 Loss: 0.007219146471470594\nEpoch: 2000 Loss: 0.006844399031251669\nEpoch: 2500 Loss: 0.00406250637024641\nEpoch: 3000 Loss: 0.0020757592283189297\nEpoch: 3500 Loss: 0.0025464375503361225\nEpoch: 4000 Loss: 0.004879282787442207\nEpoch: 4500 Loss: 0.001170627772808075\nEpoch: 5000 Loss: 0.0016236018855124712\nEpoch: 5500 Loss: 0.0015115265268832445\nEpoch: 6000 Loss: 0.0005236503202468157\nEpoch: 6500 Loss: 0.0004948751884512603\nEpoch: 7000 Loss: 0.0012785536237061024\nEpoch: 7500 Loss: 0.0006189785781316459\n\n\nTest the training process of the network by generating and displaying an animation.\n\nimages = ca.grow_animation(seed, 200)\ndisplay_animation(images)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\nAs expected, after some time the automato is startig to lose the desired shape."
  },
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": "Core",
    "section": "",
    "text": "We automatically select the device on which to run our experiments.\nWe also set a basic set of hyper parameters. These hypermeters can later be replaced by other values."
  },
  {
    "objectID": "core.html#create-animation-from-the-camodel",
    "href": "core.html#create-animation-from-the-camodel",
    "title": "Core",
    "section": "Create animation from the CAModel",
    "text": "Create animation from the CAModel\nWe’ll also incorporate the capability for the model to generate an animation depicting the cellular automaton’s evolution across multiple steps.\n\nsource\n\nshow_doc\n\n show_doc (sym, renderer=None, name:Optional[str]=None, title_level:int=3)\n\nShow signature and docstring for sym\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nsym\n\n\nSymbol to document\n\n\nrenderer\nNoneType\nNone\nOptional renderer (defaults to markdown)\n\n\nname\nstr | None\nNone\nOptionally override displayed name of sym\n\n\ntitle_level\nint\n3\nHeading level to use for symbol name\n\n\n\n\nimages = ca.grow_animation(seed, 20)\n\n\ndisplay_animation(images)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "whatpersists,exists.html",
    "href": "whatpersists,exists.html",
    "title": "Experiment 2: What persists, exists",
    "section": "",
    "text": "batch_size = 8\nn_epochs = 8000\n\n\npath = '../images/emoji_u1f98e.png'\n\n\nimg_tensor = load_image(path)\n\n\n\n\n\nPool Training\nWe want to create a pool of samples, that will contain different stages of the generation process as initial states.\n\nsource\n\nSamplePool\n\n SamplePool (pool_size=1024, loss_fn=None, device='cpu')\n\nInitialize self. See help(type(self)) for accurate signature.\nIn the SamplePool, we use a loss function to select the sample inside the batch with the highest loss and replace it with the original seed. To do so, we will use the MSE loss.\n\nsource\n\n\nmse\n\n mse (pred, target, dim=1)\n\n\nloss_fn = partial(mse, target=img_tensor.repeat(batch_size, 1, 1, 1).to(def_device))\n\n\npool = SamplePool(1024, loss_fn=loss_fn)\nbatch = pool.sample()\nbatch.shape\n\ntorch.Size([8, 16, 40, 40])\n\n\nWe also need a function that will visualize a batch of inputs to validate that the sampling of the pool works as expected.\n\nsource\n\n\nvis_batch\n\n vis_batch (batch)\n\n\nvis_batch(batch)\n\n\n\n\n\n\n\nTraining Loop\n\n# Instantiate the model\nca = CAModel(CHANNEL_N).to(def_device)\n\n# Optimization\nlr = 2e-3\nlr_gamma = 0.9999\nbetas = (0.5, 0.5)\noptimizer = torch.optim.Adam(ca.parameters(), lr=lr, betas=betas)\nscheduler = optim.lr_scheduler.ExponentialLR(optimizer, lr_gamma)\n\ntarget = img_tensor.repeat(batch_size, 1, 1, 1)\n\n\nfor i in tqdm(range(n_epochs)):\n    # zero the optimizer\n    optimizer.zero_grad()\n\n    # set the number of steps to take\n    steps = torch.randint(64, 96, (1,)).item()\n\n    # sample the pool to get the input\n    model_in = pool.sample()\n\n    # activate the model\n    res = ca(model_in, steps=steps)\n\n    # calculate the loss\n    loss = F.mse_loss(res[:, :4], target) # we only care about the RGBA channels\n\n    # update the pool\n    pool.update(res)\n\n    # log the loss\n    if i%500 == 0:\n        print(f\"Epoch: {i} Loss: {loss.item()}\")\n\n    # backpropagate the loss and update the weights\n    loss.backward()\n    optimizer.step()\n    scheduler.step()\n\n  0%|                                        | 1/8000 [00:00&lt;1:26:39,  1.54it/s]  6%|██▌                                     | 503/8000 [00:35&lt;09:04, 13.77it/s] 13%|████▉                                  | 1003/8000 [01:09&lt;07:48, 14.92it/s] 19%|███████▎                               | 1503/8000 [01:43&lt;07:31, 14.38it/s] 25%|█████████▊                             | 2003/8000 [02:17&lt;06:55, 14.43it/s] 31%|████████████▏                          | 2503/8000 [02:51&lt;06:19, 14.48it/s] 38%|██████████████▋                        | 3003/8000 [03:26&lt;05:46, 14.40it/s] 44%|█████████████████                      | 3503/8000 [04:00&lt;05:28, 13.70it/s] 50%|███████████████████▌                   | 4003/8000 [04:35&lt;04:51, 13.71it/s] 56%|█████████████████████▉                 | 4503/8000 [05:10&lt;04:02, 14.45it/s] 63%|████████████████████████▍              | 5001/8000 [05:44&lt;03:34, 14.00it/s] 69%|██████████████████████████▊            | 5503/8000 [06:23&lt;03:19, 12.54it/s] 75%|█████████████████████████████▎         | 6001/8000 [07:03&lt;02:30, 13.32it/s] 81%|███████████████████████████████▋       | 6503/8000 [07:44&lt;02:02, 12.19it/s] 88%|██████████████████████████████████▏    | 7001/8000 [08:24&lt;01:20, 12.39it/s] 94%|████████████████████████████████████▌  | 7503/8000 [09:04&lt;00:35, 13.94it/s]100%|███████████████████████████████████████| 8000/8000 [09:43&lt;00:00, 13.70it/s]\n\n\nEpoch: 0 Loss: 0.11318174749612808\nEpoch: 500 Loss: 0.025092191994190216\nEpoch: 1000 Loss: 0.015459218993782997\nEpoch: 1500 Loss: 0.008353400975465775\nEpoch: 2000 Loss: 0.0046185762621462345\nEpoch: 2500 Loss: 0.0031142488587647676\nEpoch: 3000 Loss: 0.0015645724488422275\nEpoch: 3500 Loss: 0.0010012438287958503\nEpoch: 4000 Loss: 0.0005030333995819092\nEpoch: 4500 Loss: 0.0005954373045824468\nEpoch: 5000 Loss: 0.0009438891429454088\nEpoch: 5500 Loss: 0.000864389818161726\nEpoch: 6000 Loss: 0.00047235662350431085\nEpoch: 6500 Loss: 0.00031021377071738243\nEpoch: 7000 Loss: 0.00025668973103165627\nEpoch: 7500 Loss: 0.00032552078482694924\n\n\n\nimages = ca.grow_animation(seed, 200)\ndisplay_animation(images)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\nThe automato manages to maintain it’s shape as time passes.\n\nVisualize a batch from the updated pool.\nDuring the training process we update the samples inside the pool. Let’s visualize how a sample would look like after the training process is completed.\n\nbatch = pool.sample()\n\n\nvis_batch(batch)\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers)."
  }
]